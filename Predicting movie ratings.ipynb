{"cells":[{"cell_type":"markdown","source":["##COMP 4254 - Advanced Topics in Data Analytics\n### Predicting movie ratings lab"],"metadata":{}},{"cell_type":"markdown","source":["#![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n \nOne of the most common uses of big data is to predict what users want.  This allows Google to show you relevant ads, Amazon to recommend relevant products, and Netflix to recommend movies that you might like.  This lab will demonstrate how we can use Apache Spark to recommend movies to a user.  We will start with some basic techniques, and then use the [Spark MLlib](http://spark.apache.org/docs/2.0.0/api/python/pyspark.mllib.html) library's Alternating Least Squares method to make more sophisticated predictions.\n \nFor this lab, we will use a subset dataset of 500,000 ratings from the [movielens 10M stable benchmark rating dataset](http://grouplens.org/datasets/movielens/) which you can download from D2L. However, the same code you write will work for the full dataset, or their latest dataset of 21 million ratings.\n \nIn this lab:\n* *Part 0*: Preliminaries\n* *Part 1*: Basic Recommendations\n* *Part 2*: Collaborative Filtering"],"metadata":{}},{"cell_type":"markdown","source":["#### Code\nThis assignment can be completed using basic Python and pySpark Transformations and Actions.  Libraries other than `math` are not necessary. With the exception of the ML functions that are introduced in this assignment (and `join`, which you are familiar with from COMP 2854), you should be able to complete all parts of this homework using only the Spark functions you have used in prior exercises."],"metadata":{}},{"cell_type":"markdown","source":["**WARNING:** If *test_helper*, required below, is not installed, follow the instructions in the previous lecture (word count notebook in D2L)."],"metadata":{}},{"cell_type":"code","source":["from test_helper import Test\nfrom __future__ import print_function\n\n# You may need to change the file names below after you upload your files to Databricks\nratingsFilename = '/FileStore/tables/userratings_dat-b643a.gz'\nmoviesFilename = '/FileStore/tables/movies.dat'"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["#### **Part 0: Preliminaries**\nWe read in each of the files and create an RDD consisting of parsed lines.\nEach line in the ratings dataset (`userratings.dat.gz`) is formatted as:\n  `UserID::MovieID::Rating::Timestamp`\n  \nEach line in the movies (`movies.dat`) dataset is formatted as:\n  `MovieID::Title::Genres`\n  \nThe `Genres` field has the format\n  `Genres1|Genres2|Genres3|...`\n  \nThe format of these files is uniform and simple, so we can use Python [`split()`](https://docs.python.org/2/library/stdtypes.html#str.split) to parse their lines.\nParsing the two files yields two RDDs:\n* For each line in the ratings dataset, we create a tuple of (UserID, MovieID, Rating). We drop the timestamp because we do not need it for this exercise.\n* For each line in the movies dataset, we create a tuple of (MovieID, Title). We drop the Genres because we do not need them for this exercise."],"metadata":{}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nnumPartitions = 2\nrawRatings = sc.textFile(ratingsFilename).repartition(numPartitions)\nrawMovies = sc.textFile(moviesFilename)\n\ndef get_ratings_tuple(entry):\n    \"\"\" Parse a line in the ratings dataset\n    Args:\n        entry (str): a line in the ratings dataset in the form of UserID::MovieID::Rating::Timestamp\n    Returns:\n        tuple: (UserID, MovieID, Rating) where the data types are int, int and float respectively\n    \"\"\"\n    <FILL IN>\n    return <FILL IN>\n\n\ndef get_movie_tuple(entry):\n    \"\"\" Parse a line in the movies dataset\n    Args:\n        entry (str): a line in the movies dataset in the form of MovieID::Title::Genres\n    Returns:\n        tuple: (MovieID, Title) where the data types are int and string respectively\n    \"\"\"\n    <FILL IN>\n    return <FILL IN>\n\n\nratingsRDD = rawRatings.map(get_ratings_tuple).cache()\nmoviesRDD = rawMovies.map(get_movie_tuple).cache()\n\nratingsCount = ratingsRDD.count()\nmoviesCount = moviesRDD.count()\n\nprint('There are', ratingsCount, 'ratings and', moviesCount, 'movies in the datasets')\nprint('Ratings:', ratingsRDD.take(3))\nprint('Movies:', moviesRDD.take(3))\n\nassert ratingsCount == 487650\nassert moviesCount == 3883\nassert moviesRDD.filter(lambda (id, title): title == 'Toy Story (1995)').count() == 1\nassert (ratingsRDD.takeOrdered(1, key=lambda (user, movie, rating): movie)\n        == [(1, 1, 5.0)])"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Let's take a look at the structure of ratingsRDD\nratingsRDD.take(5)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Let's take a look at the structure of moviesRDD\nmoviesRDD.take(5)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["In this lab we will be examining subsets of the tuples we create (e.g., the top rated movies by users). Whenever we examine only a subset of a large dataset, there is the potential that the result will depend on the order we perform operations, such as joins, or how the data is partitioned across the workers. What we want to guarantee is that we always see the same results for a subset, independent of how we manipulate or store the data.\n \nWe can do that by sorting before we examine a subset. You might think that the most obvious choice when dealing with an RDD of tuples would be to use the [`sortByKey()` method][sortbykey]. However this choice is problematic, as we can still end up with different results if the key is not unique.\n \nNote: It is important to use the [`unicode` type](https://docs.python.org/2/howto/unicode.html#the-unicode-type) instead of the `string` type as the titles are in unicode characters.\n \nConsider the following example, and note that while the sets are equal, the printed lists are usually in different order by value, *although they may randomly match up from time to time.*\n\n[sortbykey]: https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.sortByKey"],"metadata":{}},{"cell_type":"code","source":["tmp1 = [(1, u'alpha'), (2, u'alpha'), (2, u'beta'), (3, u'alpha'), (1, u'epsilon'), (1, u'delta')]\ntmp2 = [(1, u'delta'), (2, u'alpha'), (2, u'beta'), (3, u'alpha'), (1, u'epsilon'), (1, u'alpha')]\n\noneRDD = sc.parallelize(tmp1)\ntwoRDD = sc.parallelize(tmp2)\noneSorted = oneRDD.sortByKey(True).collect()\ntwoSorted = twoRDD.sortByKey(True).collect()\nprint(oneSorted)\nprint(twoSorted)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Even though the two lists contain identical tuples, the difference in ordering *sometimes* yields a different ordering for the sorted RDD (try running the cell repeatedly and see if the results change). If we only examined the first two elements of the RDD (e.g., using `take(2)`), then we would observe different answers - **that is a really bad outcome as we want identical input data to always yield identical output**.\n \nA better technique is to sort the RDD by *both the key and value*, which we can do by combining the key and value into a single string and then sorting on that string. Since the key is an integer and the value is a unicode string, we can combine them into a single string (e.g., `str(key) + ' ' + value`) before sorting the RDD using [sortBy()][sortby].\n[sortby]: https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.sortBy"],"metadata":{}},{"cell_type":"code","source":["def sortFunction(tuple):\n    \"\"\" Construct the sort string (does not perform actual sorting)\n    Args:\n        tuple: (rating, MovieName)\n    Returns:\n        sortString: the value to sort with, 'rating MovieName'\n    \"\"\"\n    key = str(tuple[0])\n    value = tuple[1]\n    return (key + ' ' + value)\n\n\nprint(oneRDD.sortBy(sortFunction, True).collect())\nprint(twoRDD.sortBy(sortFunction, True).collect())"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["Notice that the two sorted RDDs are now identical every time you run the previous cell. If we just want to look at the first few elements of the RDD in sorted order, we can use the [takeOrdered][takeordered] method with the `sortFunction` we defined.\n[takeordered]: https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.takeOrdered"],"metadata":{}},{"cell_type":"code","source":["oneSorted1 = oneRDD.takeOrdered(3, key=sortFunction)\ntwoSorted1 = twoRDD.takeOrdered(3, key=sortFunction)\nprint('one is', oneSorted1)\nprint('two is', twoSorted1)\nassert oneSorted1 == twoSorted1"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["#### **Part 1: Basic Recommendations**\n \nOne way to recommend movies is to always recommend the movies with the highest average rating. In this part, we will use Spark to find the name, number of ratings, and the average rating of the 20 movies with the highest average rating and more than 500 reviews. We want to filter our movies with high ratings but fewer than or equal to 500 reviews because movies with few reviews may not have broad appeal to everyone."],"metadata":{}},{"cell_type":"markdown","source":["**(1a) Number of Ratings and Average Ratings for a Movie**\n \nUsing only Python, implement a helper function `getCountsAndAverages()` that takes a single tuple of (MovieID, (Rating1, Rating2, Rating3, ...)) and returns a tuple of (MovieID, (number of ratings, averageRating)). For example, given the tuple `(100, (10.0, 20.0, 30.0))`, your function should return `(100, (3, 20.0))`"],"metadata":{}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\n# First, implement a helper function `getCountsAndAverages` using only Python\ndef getCountsAndAverages(IDandRatingsTuple):\n    \"\"\" Calculate average rating\n    Args:\n        IDandRatingsTuple: a single tuple of (MovieID, (Rating1, Rating2, Rating3, ...))\n    Returns:\n        tuple: a tuple of (MovieID, (number of ratings, averageRating))\n    \"\"\"\n    <FILL IN>\n    return <FILL IN>"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# TEST Number of Ratings and Average Ratings for a Movie (1a)\nTest.assertEquals(getCountsAndAverages((1, (1, 2, 3, 4))), (1, (4, 2.5)),\n                            'incorrect getCountsAndAverages() with integer list')\nTest.assertEquals(getCountsAndAverages((100, (10.0, 20.0, 30.0))), (100, (3, 20.0)),\n                            'incorrect getCountsAndAverages() with float list')\nTest.assertEquals(getCountsAndAverages((110, xrange(20))), (110, (20, 9.5)),\n                            'incorrect getCountsAndAverages() with xrange')"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["**(1b) Movies with Highest Average Ratings**\n \nNow that we have a way to calculate the average ratings, we will use the `getCountsAndAverages()` helper function with Spark to determine movies with highest average ratings.\n \nThe steps you should perform are:\n* Recall that the `ratingsRDD` contains tuples of the form (UserID, MovieID, Rating). From `ratingsRDD` create an RDD with tuples of the form (MovieID, Python iterable of Ratings for that MovieID). This transformation will yield an RDD of the form: `[(1, <pyspark.resultiterable.ResultIterable object at 0x7f16d50e7c90>), (2, <pyspark.resultiterable.ResultIterable object at 0x7f16d50e79d0>), (3, <pyspark.resultiterable.ResultIterable object at 0x7f16d50e7610>)]`. Note that you will only need to perform two Spark transformations to do this step.\n* Using `movieIDsWithRatingsRDD` and your `getCountsAndAverages()` helper function, compute the number of ratings and average rating for each movie to yield tuples of the form (MovieID, (number of ratings, average rating)). This transformation will yield an RDD of the form: `[(1, (993, 4.145015105740181)), (2, (332, 3.174698795180723)), (3, (299, 3.0468227424749164))]`. You can do this step with one Spark transformation."],"metadata":{}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\n# From ratingsRDD with tuples of (UserID, MovieID, Rating) create an RDD with tuples of\n# the (MovieID, iterable of Ratings for that MovieID)\nmovieIDsWithRatingsRDD = ratingsRDD.<FILL IN>\n\n# Using `movieIDsWithRatingsRDD`, compute the number of ratings and average rating for each movie to\n# yield tuples of the form (MovieID, (number of ratings, average rating))\nmovieIDsWithAvgRatingsRDD = movieIDsWithRatingsRDD.<FILL IN>\nprint('movieIDsWithAvgRatingsRDD:', movieIDsWithAvgRatingsRDD.take(3))\n"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["We want to see movie names, instead of movie IDs. The code below joins `moviesRDD` and `movieIDsWithAvgRatingsRDD` to get an RDD that looks like: `[(3.6818181818181817, u'Happiest Millionaire, The (1967)', 22), (3.0468227424749164, u'Grumpier Old Men (1995)', 299), (2.882978723404255, u'Hocus Pocus (1993)', 94)]`. You don't need to modify this code."],"metadata":{}},{"cell_type":"code","source":["# To `movieIDsWithAvgRatingsRDD`, apply RDD transformations that use `moviesRDD` to get the movie\n# names for `movieIDsWithAvgRatingsRDD`, yielding tuples of the form\n# (average rating, movie name, number of ratings)\nmovieNameWithAvgRatingsRDD = (moviesRDD\n                              .join(movieIDsWithAvgRatingsRDD)\n                              .map(lambda x: (x[1][1][1], x[1][0], x[1][1][0]))\n                              )\nprint('movieNameWithAvgRatingsRDD:', movieNameWithAvgRatingsRDD.take(3))"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# TEST Movies with Highest Average Ratings (1b)\nTest.assertEquals(movieIDsWithRatingsRDD.count(), 3615,\n                'incorrect movieIDsWithRatingsRDD.count() (expected 3615)')\nmovieIDsWithRatingsTakeOrdered = movieIDsWithRatingsRDD.takeOrdered(3)\nTest.assertTrue(movieIDsWithRatingsTakeOrdered[0][0] == 1 and\n                len(list(movieIDsWithRatingsTakeOrdered[0][1])) == 993,\n                'incorrect count of ratings for movieIDsWithRatingsTakeOrdered[0] (expected 993)')\nTest.assertTrue(movieIDsWithRatingsTakeOrdered[1][0] == 2 and\n                len(list(movieIDsWithRatingsTakeOrdered[1][1])) == 332,\n                'incorrect count of ratings for movieIDsWithRatingsTakeOrdered[1] (expected 332)')\nTest.assertTrue(movieIDsWithRatingsTakeOrdered[2][0] == 3 and\n                len(list(movieIDsWithRatingsTakeOrdered[2][1])) == 299,\n                'incorrect count of ratings for movieIDsWithRatingsTakeOrdered[2] (expected 299)')\n\nTest.assertEquals(movieIDsWithAvgRatingsRDD.count(), 3615,\n                'incorrect movieIDsWithAvgRatingsRDD.count() (expected 3615)')\nTest.assertEquals(movieIDsWithAvgRatingsRDD.takeOrdered(3),\n                [(1, (993, 4.145015105740181)), (2, (332, 3.174698795180723)),\n                 (3, (299, 3.0468227424749164))],\n                'incorrect movieIDsWithAvgRatingsRDD.takeOrdered(3)')\n\nTest.assertEquals(movieNameWithAvgRatingsRDD.count(), 3615,\n                'incorrect movieNameWithAvgRatingsRDD.count() (expected 3615)')\nTest.assertEquals(movieNameWithAvgRatingsRDD.takeOrdered(3),\n                [(1.0, u'Autopsy (Macchie Solari) (1975)', 1), (1.0, u'Better Living (1998)', 1),\n                 (1.0, u'Big Squeeze, The (1996)', 3)],\n                 'incorrect movieNameWithAvgRatingsRDD.takeOrdered(3)')"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["**(1c) Movies with Highest Average Ratings and more than 500 reviews**\n \nNow that we have an RDD of the movies with highest average ratings, we can use Spark to determine the 20 movies with highest average ratings and more than 500 reviews.\n \nApply a single RDD transformation to `movieNameWithAvgRatingsRDD` to limit the results to movies with ratings from more than 500 people. We then use the `sortFunction()` helper function to sort by the average rating to get the movies in order of their rating (highest rating first). You will end up with an RDD of the form:\n`[(4.5349264705882355, u'Shawshank Redemption, The (1994)', 1088), (4.515798462852263, u\"Schindler's List (1993)\", 1171), (4.512893982808023, u'Godfather, The (1972)', 1047)]`"],"metadata":{}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\n# Apply an RDD transformation to `movieNameWithAvgRatingsRDD` to limit the results to movies with\n# ratings from more than 500 people. We then use the `sortFunction()` helper function to sort by the\n# average rating to get the movies in order of their rating (highest rating first)\nmovieLimitedAndSortedByRatingRDD = (movieNameWithAvgRatingsRDD\n                                    .<FILL IN>\n                                    .sortBy(sortFunction, False))\nprint('Movies with highest ratings:', movieLimitedAndSortedByRatingRDD.take(20))"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["# TEST Movies with Highest Average Ratings and more than 500 Reviews (1c)\nTest.assertEquals(movieLimitedAndSortedByRatingRDD.count(), 194,\n                'incorrect movieLimitedAndSortedByRatingRDD.count()')\nTest.assertEquals(movieLimitedAndSortedByRatingRDD.take(20),\n              [(4.5349264705882355, u'Shawshank Redemption, The (1994)', 1088),\n               (4.515798462852263, u\"Schindler's List (1993)\", 1171),\n               (4.512893982808023, u'Godfather, The (1972)', 1047),\n               (4.510460251046025, u'Raiders of the Lost Ark (1981)', 1195),\n               (4.505415162454874, u'Usual Suspects, The (1995)', 831),\n               (4.457256461232604, u'Rear Window (1954)', 503),\n               (4.45468509984639, u'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 651),\n               (4.43953006219765, u'Star Wars: Episode IV - A New Hope (1977)', 1447),\n               (4.4, u'Sixth Sense, The (1999)', 1110), (4.394285714285714, u'North by Northwest (1959)', 700),\n               (4.379506641366224, u'Citizen Kane (1941)', 527), (4.375, u'Casablanca (1942)', 776),\n               (4.363975155279503, u'Godfather: Part II, The (1974)', 805),\n               (4.358816276202219, u\"One Flew Over the Cuckoo's Nest (1975)\", 811),\n               (4.358173076923077, u'Silence of the Lambs, The (1991)', 1248),\n               (4.335826477187734, u'Saving Private Ryan (1998)', 1337),\n               (4.326241134751773, u'Chinatown (1974)', 564),\n               (4.325383304940375, u'Life Is Beautiful (La Vita \\ufffd bella) (1997)', 587),\n               (4.324110671936759, u'Monty Python and the Holy Grail (1974)', 759),\n               (4.3096, u'Matrix, The (1999)', 1250)], 'incorrect sortedByRatingRDD.take(20)')"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["Using a threshold on the number of reviews is one way to improve the recommendations, but there are many other good ways to improve quality. For example, you could weight ratings by the number of ratings."],"metadata":{}},{"cell_type":"markdown","source":["## **Part 2: Collaborative Filtering**\nIn this course, you have learned about many of the basic transformations and actions that Spark allows us to apply to distributed datasets.  Spark also exposes some higher level functionality; in particular, Machine Learning using a component of Spark called [MLlib][mllib].  In this part, you will learn how to use MLlib to make personalized movie recommendations using the movie data we have been analyzing.\n \nWe are going to use a technique called [collaborative filtering][collab]. Collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a person chosen randomly. You can read more about collaborative filtering [here][collab2].\n \nThe image below (from [Wikipedia][collab]) shows an example of predicting of the user's rating using collaborative filtering. At first, people rate different items (like videos, images, games). After that, the system is making predictions about a user's rating for an item, which the user has not rated yet. These predictions are built upon the existing ratings of other users, who have similar ratings with the active user. For instance, in the image below the system has made a prediction, that the active user will not like the video.\n\n![collaborative filtering](https://courses.edx.org/c4x/BerkeleyX/CS100.1x/asset/Collaborative_filtering.gif)\n \n[mllib]: https://spark.apache.org/mllib/\n[collab]: https://en.wikipedia.org/?title=Collaborative_filtering\n[collab2]: http://recommender-systems.org/collaborative-filtering/"],"metadata":{}},{"cell_type":"markdown","source":["For movie recommendations, we start with a matrix whose entries are movie ratings by users.  Each column represents a user and each row represents a particular movie.\n \nSince not all users have rated all movies, we do not know all of the entries in this matrix, which is precisely why we need collaborative filtering.  For each user, we have ratings for only a subset of the movies.  With collaborative filtering, the idea is to approximate the ratings matrix by factorizing it as the product of two matrices: one that describes properties of each user (shown in green), and one that describes properties of each movie (shown in blue).\n \nWe want to select these two matrices such that the error for the users/movie pairs where we know the correct ratings is minimized.  The [Alternating Least Squares][als] algorithm does this by first randomly filling the users matrix with values and then optimizing the value of the movies such that the error is minimized.  Then, it holds the movies matrix constrant and optimizes the value of the user's matrix.  This alternation between which matrix to optimize is the reason for the \"alternating\" in the name.\n \n[als]: https://en.wikiversity.org/wiki/Least-Squares_Method"],"metadata":{}},{"cell_type":"markdown","source":["**(2a) Creating a Training Set**\n\nBefore we jump into using machine learning, we need to break up the `ratingsRDD` dataset into three pieces:\n* A training set (RDD), which we will use to train models\n* A validation set (RDD), which we will use to choose the best model (if you don't remember why we need this, you can refer back to assignment 3 notebook in D2L)\n* A test set (RDD), which we will use for our experiments\n\nTo randomly split the dataset into the multiple groups, we can use the pySpark [randomSplit()](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) transformation. `randomSplit()` takes a set of splits and and seed and returns multiple RDDs."],"metadata":{}},{"cell_type":"code","source":["trainingRDD, validationRDD, testRDD = ratingsRDD.randomSplit([6, 2, 2], seed=0L)\n\nprint('Training:', trainingRDD.count(), ', validation:', validationRDD.count(), ', test:', testRDD.count())\n\n#tuple: (UserID, MovieID, Rating)\nprint(trainingRDD.take(3))\nprint(validationRDD.take(3))\nprint(testRDD.take(3))\n\nassert abs(trainingRDD.count() - 293000 < 2000)\nassert abs(validationRDD.count() - 97000 < 2000)\nassert abs(testRDD.count() - 97000 < 2000)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["After splitting the dataset, your training set has about 293,000 entries and the validation and test sets each have about 97,000 entries."],"metadata":{}},{"cell_type":"markdown","source":["**(2b) Root Mean Square Error (RMSE)**\n \nIn the next part, you will generate a few different models, and will need a way to decide which model is best. We will use the [Root Mean Square Error](https://en.wikipedia.org/wiki/Root-mean-square_deviation) (RMSE) to compute the error of each model like we previously did for other regression problems.  RMSE is a frequently used measure of the differences between values (sample and population values) predicted by a model or an estimator and the values actually observed.  These individual differences are called residuals when the calculations are performed over the data sample that was used for estimation, and are called prediction errors when computed out-of-sample. The RMSE serves to aggregate the magnitudes of the errors in predictions for various times into a single measure of predictive power.\n \nSpark includes a [RegressionMetrics](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.evaluation.RegressionMetrics) module that can be used to compute the RMSE. Using this module, write a function to compute the sum of squared error given `predictedRDD` and `actualRDD` RDDs. Both RDDs consist of tuples of the form (UserID, MovieID, Rating).\n \nGiven two ratings RDDs, *x* and *y* of size *n*, we define RSME as follows: \\\\( RMSE = \\sqrt{\\frac{\\sum_{i = 1}^{n} (x_i - y_i)^2}{n}}\\\\)\n \nTo calculate RSME, the steps you should perform are:\n* Transform `predictedRDD` into the tuples of the form ((UserID, MovieID), Rating). For example, tuples like `[((1, 1), 5), ((1, 2), 3), ((1, 3), 4), ((2, 1), 3), ((2, 2), 2), ((2, 3), 4)]`. You can perform this step with a single Spark transformation.\n* Transform `actualRDD` into the tuples of the form ((UserID, MovieID), Rating). For example, tuples like `[((1, 2), 3), ((1, 3), 5), ((2, 1), 5), ((2, 2), 1)]`. You can perform this step with a single Spark transformation.\n* Using `RegressionMetrics`, compute the RMSE. Note that this will need predictions and actual values to line up, i.e. you need to match the keys so that the order is the same between `predictedRDD` and `actualRDD`. Hint: [`join`](http://spark.apache.org/docs/2.1.0/api/python/pyspark.html#pyspark.RDD.join) will help you here.\n* Make sure you pass your predicted and actual ratings as [float](https://docs.python.org/2/library/stdtypes.html#numeric-types-int-float-long-complex) values to `RegressionMetrics`, otherwise you will get an error.\n \nNote: Your solution must only use transformations and actions on RDDs. Do _not_ call `collect()` on either RDD. In general, you should try not to use `collect()` too much since you might end up transferring too much data to the driver and cause it to crash."],"metadata":{}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nimport math\nfrom pyspark.mllib.evaluation import RegressionMetrics\n\ndef computeError(predictedRDD, actualRDD):\n    \"\"\" Compute the root mean squared error between predicted and actual\n    Args:\n        predictedRDD: predicted ratings for each movie and each user where each entry is in the form\n                      (UserID, MovieID, Rating)\n        actualRDD: actual ratings where each entry is in the form (UserID, MovieID, Rating)\n    Returns:\n        RSME (float): computed RSME value\n    \"\"\"\n    # Transform predictedRDD into the tuples of the form ((UserID, MovieID), Rating)\n    predictedReformattedRDD = predictedRDD.<FILL IN>\n\n    # Transform actualRDD into the tuples of the form ((UserID, MovieID), Rating)\n    actualReformattedRDD = actualRDD.<FILL IN>\n\n    # Compute the squared error for each matching entry (i.e., the same (User ID, Movie ID) in each\n    # RDD) in the reformatted RDDs using RDD transformations\n    predictedAndActualsRDD = (predictedReformattedRDD\n                               <FILL IN>\n                             )\n    return <FILL IN>\n\n# sc.parallelize turns a Python list into a Spark RDD.\ntestPredicted = sc.parallelize([\n    (1, 1, 5),\n    (1, 2, 3),\n    (1, 3, 4),\n    (2, 1, 3),\n    (2, 2, 2),\n    (2, 3, 4)])\ntestActual = sc.parallelize([\n     (1, 2, 3),\n     (1, 3, 5),\n     (2, 1, 5),\n     (2, 2, 1)])\ntestPredicted2 = sc.parallelize([\n     (2, 2, 5),\n     (1, 2, 5)])\ntestError = computeError(testPredicted, testActual)\nprint('Error for test dataset:', testError)\n\ntestError2 = computeError(testPredicted2, testActual)\nprint('Error for test dataset2:', testError2)\n\ntestError3 = computeError(testActual, testActual)\nprint('Error for testActual dataset:', testError3)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["# TEST Root Mean Square Error (2b)\nTest.assertTrue(abs(testError - 1.22474487139) < 0.00000001,\n                'incorrect testError (expected 1.22474487139)')\nTest.assertTrue(abs(testError2 - 3.16227766017) < 0.00000001,\n                'incorrect testError2 result (expected 3.16227766017)')\nTest.assertTrue(abs(testError3 - 0.0) < 0.00000001,\n                'incorrect testActual result (expected 0.0)')"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":["**(2c) Using ALS.train()**\n \nIn this part, we will use the MLlib implementation of Alternating Least Squares, [ALS.train()](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.ALS). ALS takes a training dataset (RDD) and several parameters that control the model creation process. To determine the best values for the parameters, we will use ALS to train several models, and then we will select the best model and use the parameters from that model in the rest of this lab exercise.\n \nThe process we will use for determining the best model is as follows:\n* Pick a set of model parameters. The most important parameter to `ALS.train()` is the *rank*, which is the number of rows in the Users matrix or the number of columns in the Movies matrix. (In general, a lower rank will mean higher error on the training dataset, but a high rank may lead to [overfitting](https://en.wikipedia.org/wiki/Overfitting).)  We will train models with ranks of 4, 12, 24 and 48 using the `trainingRDD` dataset.\n* Create a model using `ALS.train(trainingRDD, rank, seed=seed, iterations=iterations, lambda_=regularizationParameter)` with three parameters: an RDD consisting of tuples of the form (UserID, MovieID, rating) used to train the model, an integer rank (4, 12, 24 or 48), a number of iterations to execute (we will use 5 for the `iterations` parameter), and a regularization coefficient (we will use 0.1 for the `regularizationParameter`).\n* For the prediction step, create an input RDD, `validationForPredictRDD`, consisting of (UserID, MovieID) pairs that you extract from `validationRDD`. You will end up with an RDD of the form: `[(1, 1287), (1, 594), (1, 1270)]`. Cache this RDD since we will be running our model multiple times with different parameters.\n* Using the model and `validationForPredictRDD`, we can predict rating values by calling [model.predictAll()](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.MatrixFactorizationModel.predictAll) with the `validationForPredictRDD` dataset, where `model` is the model we generated with ALS.train().  `predictAll` accepts an RDD with each entry in the format (userID, movieID) and outputs an RDD with each entry in the format (userID, movieID, rating).\n* Evaluate the quality of the model by using the `computeError()` function you wrote in part (2b) to compute the error between the predicted ratings and the actual ratings in `validationRDD`.\n \nWhich rank produces the best model, based on the RMSE with the `validationRDD` dataset?\n \n>Note: This operation will take a few moments to run (<half a minute)."],"metadata":{}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nfrom pyspark.mllib.recommendation import ALS\n\nvalidationForPredictRDD = validationRDD.<FILL IN>\n\nseed = 5L\niterations = 5\nregularizationParameter = 0.1\nranks = [4, 12, 24, 48]\nerrors = [0, 0, 0, 0]\nerr = 0\ntolerance = 0.03\n\nminError = float('inf')\nbestRank = -1\nbestIteration = -1\nfor rank in ranks:\n    model = ALS.train(trainingRDD, rank, seed=seed, iterations=iterations,\n                      lambda_=regularizationParameter)\n    predictedRatingsRDD = model.predictAll(<FILL IN>)\n    error = computeError(<FILL IN>)\n    errors[err] = error\n    err += 1\n    print('For rank', rank, 'the RMSE is', error)\n    if error < minError:\n        minError = error\n        bestRank = rank\n\nprint('The best model was trained with rank', bestRank)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["# TEST Using ALS.train (2c)\ntolerance = 0.03\nTest.assertEquals(trainingRDD.getNumPartitions(), 2,\n                  'incorrect number of partitions for trainingRDD (expected 2)')\nTest.assertTrue(abs(errors[0] - 0.895748227401) < tolerance, 'incorrect errors[0]: %.11f' % errors[0])\nTest.assertTrue(abs(errors[1] - 0.8913902335711) < tolerance, 'incorrect errors[1]: %.11f' % errors[1])\nTest.assertTrue(abs(errors[2] - 0.890440065696) < tolerance, 'incorrect errors[2]: %.11f' % errors[2])\nTest.assertTrue(abs(errors[3] - 0.891380196896) < tolerance, 'incorrect errors[2]: %.11f' % errors[2])"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["**(2d) Testing Your Model**\n \nSo far, we used the `trainingRDD` and `validationRDD` datasets to select the best model.  Since we used these two datasets to determine what model is best, we cannot use them to test how good the model is - otherwise we would be very vulnerable to [overfitting](https://en.wikipedia.org/wiki/Overfitting).  To decide how good our model is, we need to use the `testRDD` dataset.  We will use the `bestRank` you determined in part (2c) to create a model for predicting the ratings for the test dataset and then we will compute the RMSE.\n \nThe steps you should perform are:\n* Train a model, using the `trainingRDD`, `bestRank` from part (2c), and the parameters you used in in part (2c): `seed=seed`, `iterations=iterations`, and `lambda_=regularizationParameter` - make sure you include **all** of the parameters.\n* For the prediction step, create an input RDD, `testForPredictingRDD`, consisting of (UserID, MovieID) pairs that you extract from `testRDD`. You will end up with an RDD of the form: `[(1, 1287), (1, 594), (1, 1270)]`\n* Use [myModel.predictAll()](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.MatrixFactorizationModel.predictAll) to predict rating values for the test dataset.\n* For validation, use the `testRDD`and your `computeError` function to compute the RMSE between `testRDD` and the `predictedTestRDD` from the model.\n* Evaluate the quality of the model by using the `computeError()` function you wrote in part (2b) to compute the error between the predicted ratings and the actual ratings in `testRDD`."],"metadata":{}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nmyModel = ALS.train(trainingRDD, bestRank, seed = seed, iterations = iterations,\n                    lambda_ = regularizationParameter)\ntestForPredictingRDD = testRDD.<FILL IN>\npredictedTestRDD = myModel.<FILL IN>\n\ntestRMSE = computeError(testRDD, predictedTestRDD)\n\nprint('The model had a RMSE on the test set of', testRMSE)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["# TEST Testing Your Model (2d)\nTest.assertTrue(abs(testRMSE - 0.893085511457) < tolerance, 'incorrect testRMSE: %.11f' % testRMSE)"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":["You now have code to predict how users will rate movies! Our model predicts the rating a user will give to a movie with an expected error of 0.89 stars."],"metadata":{}}],"metadata":{"name":"COMP 4254 - Predicting movie ratings","notebookId":3},"nbformat":4,"nbformat_minor":0}
