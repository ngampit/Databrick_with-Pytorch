{"cells":[{"cell_type":"code","source":["from IPython.display import HTML\nHTML(filename='C:\\\\Users\\\\DELL\\\\DSDJ\\\\Portfolio\\\\CaseStudy\\\\Salary\\\\salary-prediction-beginner.py.html')"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#!/usr/bin/env python3\n\n# This script pulls in salary data, builds and tests several predictive models,\n# and then makes salary predictions on test data using the best model\n   \n__author__ = 'DSDJ Team'\n__email__ = 'info@datasciencedreamjob..com'\n__website__ = 'www.datasciencedreamjob.com'\n\n__copyright__ = 'Copyright 2018, Data Science Dream Job LLC'\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["def load_file(file):\n    '''loads csv to pd dataframe'''\n    return pd.read_csv(file)\n\ndef consolidate_data(df1, df2, key=None, left_index=False, right_index=False):\n    '''perform inner join to return only records that are present in both dataframes'''\n    return pd.merge(left=df1, right=df2, how='inner', on=key, left_index=left_index, right_index=right_index)\n\ndef clean_data(raw_df):\n    '''remove rows that contain salary <= 0 or duplicate job IDs'''\n    clean_df = raw_df.drop_duplicates(subset='jobId')\n    clean_df = clean_df[clean_df.salary>0]\n    return clean_df\n\ndef one_hot_encode_feature_df(df, cat_vars=None, num_vars=None):\n    '''performs one-hot encoding on all categorical variables and combines result with continous variables'''\n    cat_df = pd.get_dummies(df[cat_vars])\n    num_df = df[num_vars].apply(pd.to_numeric)\n    return pd.concat([cat_df, num_df], axis=1)#,ignore_index=False)\n\ndef get_target_df(df, target):\n    '''returns target dataframe'''\n    return df[target]\n\ndef train_model(model, feature_df, target_df, num_procs, mean_mse, cv_std):\n    neg_mse = cross_val_score(model, feature_df, target_df, cv=2, n_jobs=num_procs, scoring='neg_mean_squared_error')\n    mean_mse[model] = -1.0*np.mean(neg_mse)\n    cv_std[model] = np.std(neg_mse)\n\ndef print_summary(model, mean_mse, cv_std):\n    print('\\nModel:\\n', model)\n    print('Average MSE:\\n', mean_mse[model])\n    print('Standard deviation during CV:\\n', cv_std[model])\n\ndef save_results(model, mean_mse, predictions, feature_importances):\n    '''saves model, model summary, feature importances, and predictions'''\n    with open('model.txt', 'w') as file:\n        file.write(str(model))\n    feature_importances.to_csv('feature_importances.csv') \n    np.savetxt('predictions.csv', predictions, delimiter=',')"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["if __name__ == '__main__':\n    #define inputs\n    train_feature_file = 'C:\\\\Users\\\\DELL\\\\DSDJ\\\\Portfolio\\\\CaseStudy\\\\Salary\\\\train_features.csv'\n    train_target_file = 'C:\\\\Users\\\\DELL\\\\DSDJ\\\\Portfolio\\\\CaseStudy\\\\Salary\\\\train_salaries.csv'\n    test_feature_file = 'C:\\\\Users\\\\DELL\\\\DSDJ\\\\Portfolio\\\\CaseStudy\\\\Salary\\\\test_features.csv'\n\n    #define variables\n    categorical_vars = ['companyId', 'jobType', 'degree', 'major', 'industry']\n    numeric_vars = ['yearsExperience', 'milesFromMetropolis']\n    target_var = 'salary'"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["    #load data\n    print(\"Loading data\")\n    feature_df = load_file(train_feature_file)\n    target_df = load_file(train_target_file)\n    test_df = load_file(test_feature_file)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["    #consolidate training data\n    raw_train_df = consolidate_data(feature_df, target_df, key='jobId')"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["raw_train_df.shape"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["    #clean, shuffle, and reindex training data -- shuffling may improve cross-validation accuracy\n    clean_train_df = shuffle(clean_data(raw_train_df)).reset_index()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["    #encode categorical data and get final feature dfs\n    print(\"Encoding data\")\n    feature_df = one_hot_encode_feature_df(clean_train_df, cat_vars=categorical_vars, num_vars=numeric_vars)\n    test_df = one_hot_encode_feature_df(test_df, cat_vars=categorical_vars, num_vars=numeric_vars)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["feature_df.shape"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["test_df.shape"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["    #get target df\n    target_df = get_target_df(clean_train_df, target_var)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["    #initialize model list and dicts\n    models = []\n    mean_mse = {}\n    cv_std = {}\n    res = {}"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["    #define number of processes to run in parallel\n    num_procs = 2\n\n    #shared model paramaters\n    verbose_lvl = 5\n\n    #create models -- hyperparameter tuning already done by hand for each model\n    lr = LinearRegression()\n    lr_std_pca = make_pipeline(StandardScaler(), PCA(), LinearRegression())\n    rf = RandomForestRegressor(n_estimators=60, n_jobs=num_procs, max_depth=25, min_samples_split=60, \\\n                               max_features=30, verbose=verbose_lvl)\n    gbm = GradientBoostingRegressor(n_estimators=40, max_depth=5, loss='ls', verbose=verbose_lvl)\n\n    models.extend([lr, lr_std_pca, rf, gbm])\n\n    #parallel cross-validate models, using MSE as evaluation metric, and print summaries\n    print(\"Beginning cross validation\")\n    for model in models:\n        train_model(model, feature_df, target_df, num_procs, mean_mse, cv_std)\n        print_summary(model, mean_mse, cv_std)\n\n  "],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#choose model with lowest mse\nmodel = min(mean_mse, key=mean_mse.get)\nprint('\\nPredictions calculated using model with lowest MSE:')\nprint(model)\n\n"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["    #train model on entire dataset\n    model.fit(feature_df, target_df)\n\n    #create predictions based on test data\n    predictions = model.predict(test_df)        \n"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["    #store feature importances\n    if hasattr(model, 'feature_importances_'):\n        importances = model.feature_importances_\n    else:\n        "],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["    #linear models don't have feature_importances_\n    importances = [0]*len(feature_df.columns)\n    feature_importances = pd.DataFrame({'feature':feature_df.columns, 'importance':importances})\n    feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n    #set index to 'feature'\n    feature_importances.set_index('feature', inplace=True, drop=True)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["feature_importances"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["    #create plot\n    feature_importances[0:25].plot.bar(figsize=(20,10))\n    plt.show()\n\n"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["    #save results\n    save_results(model, mean_mse[model], predictions, feature_importances)"],"metadata":{},"outputs":[],"execution_count":21}],"metadata":{"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.4","nbconvert_exporter":"python","file_extension":".py"},"name":"DSDJ_Original Code","notebookId":3135860200143163},"nbformat":4,"nbformat_minor":0}
